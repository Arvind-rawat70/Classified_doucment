{
 "cells": [
  {
   "cell_type": "code",
   "id": "c33a8a34",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d20a7543",
   "metadata": {},
   "outputs": [],
   "source": "df = pd.read_csv(\"data/classified_documents_1000.csv\")\n"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476179e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A new training ground is under construction. T...</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The defense department released a statement on...</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Risk assessment completed for sensitive coasta...</td>\n",
       "      <td>Confidential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A new training ground is under construction. A...</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New encryption standard for secure transmissio...</td>\n",
       "      <td>Secret</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text         label\n",
       "0  A new training ground is under construction. T...        Public\n",
       "1  The defense department released a statement on...        Public\n",
       "2  Risk assessment completed for sensitive coasta...  Confidential\n",
       "3  A new training ground is under construction. A...        Public\n",
       "4  New encryption standard for secure transmissio...        Secret"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9714887d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.count of 0           Public\n",
       "1           Public\n",
       "2     Confidential\n",
       "3           Public\n",
       "4           Secret\n",
       "          ...     \n",
       "95          Public\n",
       "96          Public\n",
       "97          Public\n",
       "98    Confidential\n",
       "99    Confidential\n",
       "Name: label, Length: 100, dtype: object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].unique()\n",
    "df['label'].count"
   ]
  },
  {
   "cell_type": "code",
   "id": "625e352f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "from nltk.stem import PorterStemmer"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc07285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25f23379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_text(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('','',string.punctuation))\n",
    "    text = re.sub(r'\\d+', '',text)\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Stemming (optional, can replace with lemmatization if needed)\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # Join back into string\n",
    "    cleaned = ' '.join(tokens)\n",
    "    \n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33903232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['text'].apply(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b3091e9",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "159306b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Label_encoder = LabelEncoder()\n",
    "df['encoded_label'] = Label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c523e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['cleaned_text']\n",
    "y = df['encoded_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88613f40",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'new train ground construct defens depart releas statement peacekeep effort defens depart releas statement peacekeep effort exhibit histor weapon open public defens depart releas statement peacekeep effort armi host chariti event next week new train ground construct defens depart releas statement peacekeep effort defens depart releas statement peacekeep effort defens depart releas statement peacekeep effort new train ground construct defens depart releas statement peacekeep effort defens depart releas statement peacekeep effort new train ground construct defens depart releas statement peacekeep effort armi host chariti event next week defens depart releas statement peacekeep effort public recruit process start august'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[35], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m classification_report, accuracy_score\n\u001B[0;32m      3\u001B[0m vectorize \u001B[38;5;241m=\u001B[39m TfidfTransformer()\n\u001B[1;32m----> 4\u001B[0m x_vec \u001B[38;5;241m=\u001B[39m \u001B[43mvectorize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mc:\\Users\\arvind rawat\\OneDrive\\Desktop\\classifed_doucment\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    314\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    315\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 316\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    318\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    319\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    320\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    321\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    322\u001B[0m         )\n",
      "File \u001B[1;32mc:\\Users\\arvind rawat\\OneDrive\\Desktop\\classifed_doucment\\.venv\\lib\\site-packages\\sklearn\\base.py:892\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    877\u001B[0m         warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    878\u001B[0m             (\n\u001B[0;32m    879\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis object (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) has a `transform`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    887\u001B[0m             \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[0;32m    888\u001B[0m         )\n\u001B[0;32m    890\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    891\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[1;32m--> 892\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m    893\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    894\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m    895\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32mc:\\Users\\arvind rawat\\OneDrive\\Desktop\\classifed_doucment\\.venv\\lib\\site-packages\\sklearn\\base.py:1363\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1356\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1358\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1359\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1360\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1361\u001B[0m     )\n\u001B[0;32m   1362\u001B[0m ):\n\u001B[1;32m-> 1363\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\Users\\arvind rawat\\OneDrive\\Desktop\\classifed_doucment\\.venv\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1654\u001B[0m, in \u001B[0;36mTfidfTransformer.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m   1636\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Learn the idf vector (global term weights).\u001B[39;00m\n\u001B[0;32m   1637\u001B[0m \n\u001B[0;32m   1638\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1649\u001B[0m \u001B[38;5;124;03m    Fitted transformer.\u001B[39;00m\n\u001B[0;32m   1650\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1651\u001B[0m \u001B[38;5;66;03m# large sparse data is not supported for 32bit platforms because\u001B[39;00m\n\u001B[0;32m   1652\u001B[0m \u001B[38;5;66;03m# _document_frequency uses np.bincount which works on arrays of\u001B[39;00m\n\u001B[0;32m   1653\u001B[0m \u001B[38;5;66;03m# dtype NPY_INTP which is int32 for 32bit platforms. See #20923\u001B[39;00m\n\u001B[1;32m-> 1654\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mvalidate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1655\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_IS_32BIT\u001B[49m\n\u001B[0;32m   1656\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1657\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m sp\u001B[38;5;241m.\u001B[39missparse(X):\n\u001B[0;32m   1658\u001B[0m     X \u001B[38;5;241m=\u001B[39m sp\u001B[38;5;241m.\u001B[39mcsr_matrix(X)\n",
      "File \u001B[1;32mc:\\Users\\arvind rawat\\OneDrive\\Desktop\\classifed_doucment\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001B[0m, in \u001B[0;36mvalidate_data\u001B[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[0m\n\u001B[0;32m   2952\u001B[0m         out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m   2953\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[1;32m-> 2954\u001B[0m     out \u001B[38;5;241m=\u001B[39m check_array(X, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m   2955\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[0;32m   2956\u001B[0m     out \u001B[38;5;241m=\u001B[39m _check_y(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n",
      "File \u001B[1;32mc:\\Users\\arvind rawat\\OneDrive\\Desktop\\classifed_doucment\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:1053\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m   1051\u001B[0m         array \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(array, dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1052\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1053\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1054\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[0;32m   1055\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1056\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[0;32m   1057\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[1;32mc:\\Users\\arvind rawat\\OneDrive\\Desktop\\classifed_doucment\\.venv\\lib\\site-packages\\sklearn\\utils\\_array_api.py:757\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[1;34m(array, dtype, order, copy, xp, device)\u001B[0m\n\u001B[0;32m    755\u001B[0m     array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39marray(array, order\u001B[38;5;241m=\u001B[39morder, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    756\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 757\u001B[0m     array \u001B[38;5;241m=\u001B[39m \u001B[43mnumpy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    759\u001B[0m \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[0;32m    760\u001B[0m \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n\u001B[0;32m    761\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array)\n",
      "File \u001B[1;32mc:\\Users\\arvind rawat\\OneDrive\\Desktop\\classifed_doucment\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1033\u001B[0m, in \u001B[0;36mSeries.__array__\u001B[1;34m(self, dtype, copy)\u001B[0m\n\u001B[0;32m   1030\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m   1031\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1032\u001B[0m     \u001B[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001B[39;00m\n\u001B[1;32m-> 1033\u001B[0m     arr \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1034\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1035\u001B[0m     arr \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(values, dtype\u001B[38;5;241m=\u001B[39mdtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'new train ground construct defens depart releas statement peacekeep effort defens depart releas statement peacekeep effort exhibit histor weapon open public defens depart releas statement peacekeep effort armi host chariti event next week new train ground construct defens depart releas statement peacekeep effort defens depart releas statement peacekeep effort defens depart releas statement peacekeep effort new train ground construct defens depart releas statement peacekeep effort defens depart releas statement peacekeep effort new train ground construct defens depart releas statement peacekeep effort armi host chariti event next week defens depart releas statement peacekeep effort public recruit process start august'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "vectorize = TfidfTransformer()\n",
    "x_vec = vectorize.fit_transform(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "783bd450",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "705fbda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['encoded_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "018d519e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Series.count of 0     1\n",
       "1     1\n",
       "2     0\n",
       "3     1\n",
       "4     2\n",
       "     ..\n",
       "95    1\n",
       "96    1\n",
       "97    1\n",
       "98    0\n",
       "99    0\n",
       "Name: encoded_label, Length: 100, dtype: int64>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['encoded_label'].count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "413f5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['text', 'label'], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cb040c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new train ground construct defens depart relea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>defens depart releas statement peacekeep effor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>risk assess complet sensit coastal region risk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new train ground construct exhibit histor weap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new encrypt standard secur transmiss approv nu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>defens depart releas statement peacekeep effor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>public recruit process start august exhibit hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>exhibit histor weapon open public armi host ch...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>risk assess complet sensit coastal region surv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>commun breakdown observ recent exercis intern ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleaned_text  encoded_label\n",
       "0   new train ground construct defens depart relea...              1\n",
       "1   defens depart releas statement peacekeep effor...              1\n",
       "2   risk assess complet sensit coastal region risk...              0\n",
       "3   new train ground construct exhibit histor weap...              1\n",
       "4   new encrypt standard secur transmiss approv nu...              2\n",
       "..                                                ...            ...\n",
       "95  defens depart releas statement peacekeep effor...              1\n",
       "96  public recruit process start august exhibit hi...              1\n",
       "97  exhibit histor weapon open public armi host ch...              1\n",
       "98  risk assess complet sensit coastal region surv...              0\n",
       "99  commun breakdown observ recent exercis intern ...              0\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0fe5f56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[1;32m----> 2\u001B[0m x_train, x_test, y_trian, y_test \u001B[38;5;241m=\u001B[39m train_test_split(\u001B[43mx_vec\u001B[49m,y,test_size\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.25\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m42\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'x_vec' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_trian, y_test = train_test_split(x_vec,y,test_size= 0.25, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10ab0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "logistic.fit(x_train,y_train)\n",
    "y_pred = logistic.predict(x_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
